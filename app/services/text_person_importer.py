"""
è‡ªç”±æ–‡æœ¬äººç‰©ä¿¡æ¯å¯¼å…¥æœåŠ¡
- ä»ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¸­æå–äººç‰©å…³é”®ä¿¡æ¯
- å°†äººç‰©æ¡£æ¡ˆä»¥JSONå½¢å¼å­˜å‚¨åœ¨æœ¬åœ°(data/persons.json)
"""

import os
import re
import json
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional

from app.models.person import PersonProfile
from app.core.logger import logger, log_audit

try:
    import yaml
except Exception:
    yaml = None

DATA_DIR = "data"
PERSONS_FILE = os.path.join(DATA_DIR, "persons.json")

EMAIL_REGEX = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
# æ›´ä¸¥æ ¼çš„æ‰‹æœºå·/åº§æœºåŒ¹é…ï¼š
MOBILE_REGEX = re.compile(r"(?:\+?86[- ]?)?(1[3-9]\d{9})(?!\d)")
LANDLINE_REGEX = re.compile(r"(?:\+?\d{1,3}[- ]?)?(0\d{2,3})[- ]?(\d{7,8})(?!\d)")
NAME_LABEL_REGEX = re.compile(r"(?:å§“å|Name)\s*[:ï¼š]\s*([^\nï¼Œã€‚;ï¼›]+)")
ADDRESS_LABEL_REGEX = re.compile(r"(?:åœ°å€|ä½å€|å±…ä½åœ°|å±…ä½åœ°å€|æˆ·ç±åœ°å€|å¿«é€’åœ°å€|Address)\s*[:ï¼š]\s*([^\n;ï¼›]+)")
COMPANY_REGEX = re.compile(r"(?:å…¬å¸|ä»»èŒäº|åœ¨)\s*([^\nï¼Œã€‚;ï¼›]+?å…¬å¸)")
POSITION_REGEX = re.compile(r"(?:èŒä½|èŒåŠ¡|å²—ä½|æ‹…ä»»)\s*[:ï¼š]?\s*([^\nï¼Œã€‚;ï¼›]+)")
EDU_REGEX = re.compile(r"(?:æ¯•ä¸šäº|å°±è¯»äº|å­¦ä¹ äº|å­¦å†|Education)\s*[:ï¼š]?\s*([^\n]+)")
SKILLS_REGEX = re.compile(r"(?:æŠ€èƒ½|Skills?)\s*[:ï¼š]\s*([^\n]+)")
GENDER_REGEX = re.compile(r"(?:æ€§åˆ«|Gender)\s*[:ï¼š]\s*([^\nï¼Œã€‚;ï¼›]+)")
BIRTH_REGEX = re.compile(r"(?:å‡ºç”Ÿ(?:å¹´æœˆ|æ—¥æœŸ|æ—¶é—´)?|ç”Ÿæ—¥|Birth(?:day| date)?)\s*[:ï¼š]\s*([^\nï¼Œã€‚;ï¼›]+)")
ID_REGEX = re.compile(r"\b(\d{6})(\d{8})(\d{3}[0-9Xx])\b")  # ç²—ç•¥åŒ¹é…18ä½èº«ä»½è¯
ID15_REGEX = re.compile(r"\b\d{15}\b")
LICENSE_PLATE_REGEX = re.compile(r"[\u4e00-\u9fa5][A-Z][A-Z0-9]{5}[A-Z0-9æŒ‚å­¦è­¦æ¸¯æ¾³]?")
HUKOU_PLACE_REGEX = re.compile(r"(?:å‡ºç”Ÿåœ°|ç±è´¯|æˆ·ç±åœ°|æˆ·å£æ‰€åœ¨åœ°)\s*[:ï¼š]\s*([^\n;ï¼›]+)")
HUKOU_ADDR_STRICT_REGEX = re.compile(r"(?:çœŸæˆ·ç±åœ°å€|æˆ·ç±åœ°åœ°å€|æˆ·å£åœ°å€)\s*[:ï¼š]\s*([^\n;ï¼›]+)")
HOUSEHOLD_LABELS = ["åŒæˆ·äºº", "åŒæˆ·", "åŒä½äºº", "å®¶åº­æˆå‘˜", "æˆ·ä¸»", "household", "household_members"]

SOCIAL_KEYS = {
    "å¾®ä¿¡": "wechat",
    "weixin": "wechat",
    "wechat": "wechat",
    "qq": "qq",
    "QQ": "qq",
    "å¾®åš": "weibo",
    "æŠ–éŸ³": "douyin",
    "telegram": "telegram",
    "tg": "telegram",
    "twitter": "twitter",
    "æ¨ç‰¹": "twitter",
    "github": "github",
    "gitee": "gitee",
    "é¢†è‹±": "linkedin",
    "linkedin": "linkedin"
}

SOCIAL_WEIBO_REGEX = re.compile(r"https?://[\w\.]*weibo\.cn/[\w/\-?=&%]+", re.IGNORECASE)


def ensure_storage():
    os.makedirs(DATA_DIR, exist_ok=True)
    if not os.path.exists(PERSONS_FILE):
        with open(PERSONS_FILE, 'w', encoding='utf-8') as f:
            json.dump([], f, ensure_ascii=False, indent=2)


def load_all_persons() -> List[Dict[str, Any]]:
    ensure_storage()
    try:
        if not os.path.exists(PERSONS_FILE) or os.path.getsize(PERSONS_FILE) == 0:
            return []
        with open(PERSONS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–persons.jsonå¤±è´¥ï¼Œå°†ä½¿ç”¨ç©ºåˆ—è¡¨: {e}")
        return []


def save_all_persons(persons: List[Dict[str, Any]]):
    with open(PERSONS_FILE, 'w', encoding='utf-8') as f:
        json.dump(persons, f, ensure_ascii=False, indent=2)


def parse_free_text_to_profile(text: str) -> PersonProfile:
	"""ä»è‡ªç”±æ–‡æœ¬ä¸­è§£æäººç‰©ä¿¡æ¯ï¼Œä½¿ç”¨AIå¢å¼ºçš„æ™ºèƒ½è§£æ"""
	text = (text or '').strip()
	if not text:
		raise ValueError("ç©ºæ–‡æœ¬æ— æ³•è§£æ")

	# ğŸš€ ä½¿ç”¨æ™ºèƒ½è§£æå™¨ï¼ˆä¼˜å…ˆä½¿ç”¨jiebaç‰ˆæœ¬ï¼Œå¤‡é€‰AIç‰ˆæœ¬ï¼‰
	try:
		# ä¼˜å…ˆä½¿ç”¨åŸºäºjiebaçš„æ™ºèƒ½è§£æå™¨
		from app.services.smart_text_parser import smart_parser
		smart_result = smart_parser.parse_text_intelligent(text)
		
		
		# è½¬æ¢è§£æç»“æœä¸ºPersonProfileæ ¼å¼
		profile = _convert_smart_result_to_profile(smart_result, text)
		return profile
		
	except ImportError:
		logger.warning("jiebaåº“æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨AIè§£æå™¨")
		try:
			from app.services.ai_text_parser import ai_parser
			ai_result = ai_parser.parse_text_intelligent(text)
			profile = _convert_ai_result_to_profile(ai_result, text)
			return profile
		except Exception as e:
			logger.warning(f"AIè§£æå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•: {e}")
			return _parse_with_traditional_method(text)
		
	except Exception as e:
		logger.warning(f"æ™ºèƒ½è§£æå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•: {e}")
		# å›é€€åˆ°ä¼ ç»Ÿè§£ææ–¹æ³•
		return _parse_with_traditional_method(text)


def _convert_smart_result_to_profile(smart_result: Dict[str, Any], original_text: str) -> PersonProfile:
	"""å°†æ™ºèƒ½è§£æç»“æœè½¬æ¢ä¸ºPersonProfileå¯¹è±¡"""
	# æ™ºèƒ½è§£æå™¨å’ŒAIè§£æå™¨çš„ç»“æœæ ¼å¼ç›¸åŒï¼Œå¯ä»¥å¤ç”¨è½¬æ¢é€»è¾‘
	return _convert_ai_result_to_profile(smart_result, original_text)


def _convert_ai_result_to_profile(ai_result: Dict[str, Any], original_text: str) -> PersonProfile:
	"""å°†AIè§£æç»“æœè½¬æ¢ä¸ºPersonProfileå¯¹è±¡"""
	main_fields = ai_result.get('main_person', {})
	household_members = ai_result.get('household_members', [])
	
	# æå–åŸºæœ¬å­—æ®µ
	name = main_fields.get('å§“å') or main_fields.get('name', 'æœªçŸ¥å§“å')
	gender = main_fields.get('æ€§åˆ«') or main_fields.get('gender')
	birth_date = None
	
	# æ—¥æœŸå¤„ç†
	birth_info = (main_fields.get('å‡ºç”Ÿæ—¥æœŸ') or main_fields.get('å‡ºç”Ÿå¹´æœˆ') or 
	             main_fields.get('birth_date') or main_fields.get('ç”Ÿæ—¥'))
	if birth_info:
		birth_date = try_parse_date(str(birth_info))
	
	# è”ç³»æ–¹å¼å¤„ç†
	emails = []
	phones = []
	
	# ç”µè¯å¤„ç†
	phone_fields = ['ç”µè¯', 'æ‰‹æœº', 'æ‰‹æœºå·', 'phone', 'mobile']
	for field in phone_fields:
		if field in main_fields:
			phone_value = main_fields[field]
			if isinstance(phone_value, list):
				phones.extend([str(p) for p in phone_value])
			else:
				phones.append(str(phone_value))
	
	# é‚®ç®±å¤„ç†
	email_fields = ['é‚®ç®±', 'email', 'é‚®ä»¶']
	for field in email_fields:
		if field in main_fields:
			email_value = main_fields[field]
			if isinstance(email_value, list):
				emails.extend([str(e) for e in email_value])
			else:
				emails.append(str(email_value))
	
	# åœ°å€å¤„ç†
	addresses = []
	address_fields = ['åœ°å€', 'ä½å€', 'address', 'å±…ä½åœ°']
	for field in address_fields:
		if field in main_fields:
			addr_value = main_fields[field]
			if isinstance(addr_value, list):
				addresses.extend([str(a) for a in addr_value])
			else:
				addresses.append(str(addr_value))
	
	# èº«ä»½è¯å¤„ç†
	id_numbers = []
	id_fields = ['èº«ä»½è¯å·', 'èº«ä»½è¯', 'id_number', 'è¯ä»¶å·']
	for field in id_fields:
		if field in main_fields:
			id_value = main_fields[field]
			if isinstance(id_value, list):
				id_numbers.extend([str(i) for i in id_value])
			else:
				id_numbers.append(str(id_value))
	
	# èŒä¸šä¿¡æ¯
	current_job = (main_fields.get('èŒä¸š') or main_fields.get('èŒä½') or 
	              main_fields.get('å·¥ä½œ') or main_fields.get('job'))
	current_company = (main_fields.get('å…¬å¸') or main_fields.get('å·¥ä½œå•ä½') or 
	                  main_fields.get('company'))
	
	# æˆ·ç±ä¿¡æ¯
	hukou_place = (main_fields.get('æˆ·ç±åœ°') or main_fields.get('ç±è´¯') or 
	              main_fields.get('å‡ºç”Ÿåœ°'))
	hukou_address = (main_fields.get('æˆ·ç±åœ°å€') or main_fields.get('çœŸæˆ·ç±åœ°å€') or 
	                main_fields.get('æˆ·å£åœ°å€'))
	
	# æ„å»ºè‡ªå®šä¹‰å±æ€§ï¼ˆæ’é™¤å·²å¤„ç†çš„æ ‡å‡†å­—æ®µï¼‰
	standard_fields = {
		'å§“å', 'name', 'æ€§åˆ«', 'gender', 'å‡ºç”Ÿæ—¥æœŸ', 'å‡ºç”Ÿå¹´æœˆ', 'birth_date', 'ç”Ÿæ—¥',
		'ç”µè¯', 'æ‰‹æœº', 'æ‰‹æœºå·', 'phone', 'mobile', 'é‚®ç®±', 'email', 'é‚®ä»¶',
		'åœ°å€', 'ä½å€', 'address', 'å±…ä½åœ°', 'èº«ä»½è¯å·', 'èº«ä»½è¯', 'id_number', 'è¯ä»¶å·',
		'èŒä¸š', 'èŒä½', 'å·¥ä½œ', 'job', 'å…¬å¸', 'å·¥ä½œå•ä½', 'company',
		'æˆ·ç±åœ°', 'ç±è´¯', 'å‡ºç”Ÿåœ°', 'æˆ·ç±åœ°å€', 'çœŸæˆ·ç±åœ°å€', 'æˆ·å£åœ°å€'
	}
	
	custom_attrs = {k: v for k, v in main_fields.items() if k not in standard_fields}
	
	# æ„å»ºå…³ç³»æ•°æ®ï¼ˆåŒæˆ·äººï¼‰
	relationships = []
	for member in household_members:
		member_name = member.get('å§“å') or member.get('name')
		if member_name and member_name != name:
			relationships.append({
				"type": "household_member",
				"name": member_name,
				"relationship": "åŒæˆ·äºº",
				"details": member,
				"source": "ai_import"
			})
	
	# åˆ›å»ºPersonProfileå¯¹è±¡
	profile = PersonProfile(
		id=str(uuid.uuid4()),
		name=str(name),
		email=emails[0] if emails else None,
		phone=phones[0] if phones else None,
		phones=phones,
		address=addresses[0] if addresses else None,
		delivery_addresses=addresses[1:] if len(addresses) > 1 else [],
		current_company=str(current_company) if current_company else None,
		current_job=str(current_job) if current_job else None,
		gender=str(gender) if gender else None,
		birth_date=birth_date,
		education=[],
		skills=[],
		social_profiles={},
		hukou_place=str(hukou_place) if hukou_place else None,
		hukou_address=str(hukou_address) if hukou_address else None,
		custom_attributes=custom_attrs,
		raw_text=original_text,
		id_numbers=id_numbers,
		relationships=relationships,
		data_sources=[{
			"type": "ai_import", 
			"timestamp": datetime.now().isoformat(),
			"confidence": ai_result.get('confidence_score', 0.8),
			"method": ai_result.get('parsing_method', 'ai')
		}],
		confidence_score=ai_result.get('confidence_score', 0.8),
		created_at=datetime.now(),
		updated_at=datetime.now(),
		verified=False
	)
	
	return profile


def _parse_with_traditional_method(text: str) -> PersonProfile:
	"""ä¼ ç»Ÿè§£ææ–¹æ³•ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
	# é¢„è§£æï¼šè‹¥æ–‡æœ¬æ˜¯JSONæˆ–YAMLï¼Œä¼˜å…ˆæŒ‰ç»“æ„åŒ–è½½å…¥
	structured: Dict[str, Any] = {}
	if (text.startswith('{') and text.endswith('}')) or (text.startswith('[') and text.endswith(']')):
		try:
			structured = json.loads(text)
		except Exception:
			structured = {}
	elif yaml and any(k in text.lower() for k in [':', 'ï¼š']) and '\n' in text:
		try:
			loaded = yaml.safe_load(text)
			structured = loaded if isinstance(loaded, dict) else {}
		except Exception:
			structured = {}

	# ğŸ” æ™ºèƒ½åˆ†ææ–‡æœ¬ç»“æ„ï¼Œè¯†åˆ«ä¸»äººç‰©å’ŒåŒæˆ·äººä¿¡æ¯
	main_person_section, household_members_info = _split_main_and_household_info(text)
	
	# ä»ä¸»äººç‰©æ®µè½è§£æä¿¡æ¯
	name = _extract(NAME_LABEL_REGEX, main_person_section) or (structured.get('name') if isinstance(structured, dict) else None)
	
	# å¦‚æœä¸»æ®µè½æ²¡æœ‰å§“åï¼Œå°è¯•ä»å®Œæ•´æ–‡æœ¬ç¬¬ä¸€ä¸ªå§“åè¡Œè·å–
	if not name:
		first_name_match = NAME_LABEL_REGEX.search(text)
		if first_name_match:
			name = first_name_match.group(1).strip()

	# é‚®ç®±ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	emails = extract_emails(main_person_section)
	if isinstance(structured, dict):
		for k in ['email', 'emails', 'é‚®ç®±']:
			v = structured.get(k)
			if isinstance(v, str):
				emails.extend(extract_emails(v))
			elif isinstance(v, list):
				for e in v:
					if isinstance(e, str):
						emails.extend(extract_emails(e))
	emails = deduplicate_preserve_order(emails)

	# æ›´æ™ºèƒ½çš„ç”µè¯æå–ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼Œé¿å…æŠŠåŒæˆ·äººç”µè¯å½“æˆä¸»äººç”µè¯ï¼‰
	phone_list = extract_phones(main_person_section)
	if isinstance(structured, dict):
		for k in ['phone', 'tel', 'mobile', 'æ‰‹æœºå·', 'ç”µè¯', 'è”ç³»ç”µè¯']:
			v = structured.get(k)
			if isinstance(v, str):
				phone_list.extend(extract_phones(v))
			elif isinstance(v, list):
				for item in v:
					if isinstance(item, str):
						phone_list.extend(extract_phones(item))
	phone_list = deduplicate_preserve_order(phone_list)

	# åœ°å€ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	addresses = extract_addresses(main_person_section)
	if isinstance(structured, dict):
		for k in ['address', 'addresses', 'åœ°å€', 'ä½å€', 'å±…ä½åœ°', 'å±…ä½åœ°å€', 'æˆ·ç±åœ°å€', 'å¿«é€’åœ°å€']:
			v = structured.get(k)
			if isinstance(v, str):
				addresses.append(v)
			elif isinstance(v, list):
				for a in v:
					if isinstance(a, str):
						addresses.append(a)
	addresses = [a.strip() for a in addresses if a and a.strip()]
	addresses = deduplicate_preserve_order(addresses)

	current_company = _extract(COMPANY_REGEX, main_person_section) or (structured.get('company') or structured.get('current_company') if isinstance(structured, dict) else None)
	current_job = _extract(POSITION_REGEX, main_person_section) or (structured.get('position') or structured.get('current_job') if isinstance(structured, dict) else None)
	
	# æ€§åˆ«è¯†åˆ« - å¢å¼ºè¯†åˆ«é€»è¾‘
	gender = _extract(GENDER_REGEX, main_person_section) or (structured.get('gender') if isinstance(structured, dict) else None)
	if not gender:
		# ä»"å…¶ä»–"å­—æ®µæˆ–æ–‡æœ¬ä¸­ç›´æ¥æœç´¢
		if 'å¥³' in main_person_section and 'ç”·' not in main_person_section:
			gender = 'å¥³'
		elif 'ç”·' in main_person_section and 'å¥³' not in main_person_section:
			gender = 'ç”·'

	# æˆ·ç±åœ°/æˆ·ç±åœ°å€ï¼ˆå¯èƒ½åœ¨ä¸»æ®µè½æˆ–å…¨æ–‡ï¼‰
	hukou_place = _extract(HUKOU_PLACE_REGEX, main_person_section) or _extract(HUKOU_PLACE_REGEX, text) or (structured.get('hukou_place') if isinstance(structured, dict) else None)
	hukou_address = _extract(HUKOU_ADDR_STRICT_REGEX, main_person_section) or _extract(HUKOU_ADDR_STRICT_REGEX, text) or (structured.get('hukou_address') if isinstance(structured, dict) else None)

	# èº«ä»½è¯ä¸è½¦ç‰Œï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	id_numbers = extract_id_numbers(main_person_section)
	plates = extract_license_plates(main_person_section)

	# å‡ºç”Ÿæ—¥æœŸï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	birth_info = _extract(BIRTH_REGEX, main_person_section)
	birth_date = try_parse_date(birth_info) if birth_info else None

	# æ•™è‚²ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	education_entries: List[Dict[str, Any]] = []
	edu_line = _extract(EDU_REGEX, main_person_section)
	if edu_line:
		education_entries.append({"text": edu_line})
	if isinstance(structured, dict) and structured.get('education'):
		if isinstance(structured['education'], list):
			education_entries.extend(structured['education'])
		elif isinstance(structured['education'], str):
			education_entries.append({"text": structured['education']})

	# æŠ€èƒ½ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	skills: List[str] = []
	skills_line = _extract(SKILLS_REGEX, main_person_section)
	if skills_line:
		for token in re.split(r"[ã€,ï¼Œ/|\\]\s*", skills_line):
			if token.strip():
				skills.append(token.strip())
	if isinstance(structured, dict) and structured.get('skills'):
		if isinstance(structured['skills'], list):
			skills.extend([str(s) for s in structured['skills']])
		elif isinstance(structured['skills'], str):
			skills.extend([s.strip() for s in re.split(r"[ã€,ï¼Œ/|\\]\s*", structured['skills']) if s.strip()])
	skills = deduplicate_preserve_order(skills)

	# è¯†åˆ«ç¤¾äº¤è´¦å·ï¼ˆåªä»ä¸»äººç‰©æ®µè½æå–ï¼‰
	social_profiles: Dict[str, str] = {}
	if isinstance(structured, dict):
		for raw_key, std_key in SOCIAL_KEYS.items():
			# ä¼˜å…ˆç»“æ„åŒ–é‡Œå¯¹åº”é”®
			if raw_key in structured and isinstance(structured[raw_key], str):
				social_profiles[std_key] = str(structured[raw_key]).strip()
			elif std_key in structured and isinstance(structured[std_key], str):
				social_profiles[std_key] = str(structured[std_key]).strip()
	# weiboé“¾æ¥ç›´æ¥è¯†åˆ«ï¼ˆä»ä¸»æ®µè½ï¼‰
	m = SOCIAL_WEIBO_REGEX.search(main_person_section)
	if m:
		social_profiles['weibo'] = m.group(0)

	# ğŸ  å¤„ç†åŒæˆ·äººä¿¡æ¯
	household_members = []
	if household_members_info:
		try:
			household_members = _parse_household_members(household_members_info)
		except Exception as e:
			logger.warning(f"è§£æåŒæˆ·äººä¿¡æ¯å¤±è´¥: {e}")

	# ğŸ” æ™ºèƒ½æå–è‡ªå®šä¹‰å­—æ®µï¼ˆä»ä¸»äººç‰©æ®µè½ï¼‰
	custom_attrs = _extract_dynamic_fields(main_person_section)

	# ä¸»å­—æ®µï¼šé€‰ä¸€ä¸ªä¸»é‚®ç®±/ç”µè¯/åœ°å€
	primary_email = emails[0] if emails else None
	primary_phone = phone_list[0] if phone_list else None
	primary_address = addresses[0] if addresses else None

	# å…¶ä»–å¤šå€¼å­—æ®µ
	delivery_addresses = [a for a in addresses if a != primary_address]

	# æ„å»ºå…³ç³»æ•°æ®ï¼ˆåŒæˆ·äººå…³ç³»ï¼‰
	relationships = []
	for member in household_members:
		member_name = member.get('name', '').strip()
		# è¿‡æ»¤ä¸»äººç‰©æœ¬äººå’Œæ— æ•ˆå§“å
		if (member_name 
			and member_name != name 
			and member_name not in ['å…¶ä»–', 'å§“å', 'èº«ä»½è¯å·ç ', 'å‡ºç”Ÿå¹´æœˆ']
			and len(member_name) >= 2):
			relationships.append({
				"type": "household_member",
				"name": member_name,
				"relationship": member.get('relationship', 'åŒæˆ·äºº'),
				"details": member,
				"source": "text_import"
			})

	profile = PersonProfile(
		id=str(uuid.uuid4()),
		name=name or "æœªçŸ¥å§“å",
		email=primary_email,
		phone=primary_phone,
		phones=phone_list,
		address=primary_address,
		delivery_addresses=delivery_addresses,
		current_company=current_company,
		current_job=current_job,
		gender=gender,
		birth_date=birth_date,
		education=education_entries,
		skills=skills,
		social_profiles=social_profiles,
		hukou_place=hukou_place,
		hukou_address=hukou_address,
		custom_attributes=custom_attrs,  # ğŸ”¥ ä¿å­˜åŠ¨æ€æ£€æµ‹çš„è‡ªå®šä¹‰å­—æ®µ
		raw_text=text,
		id_numbers=id_numbers,
		relationships=relationships,  # ğŸ”¥ ä¿å­˜åŒæˆ·äººå…³ç³»
		data_sources=[{"type": "manual_import", "timestamp": datetime.now().isoformat()}],
		confidence_score=0.8,
		created_at=datetime.now(),
		updated_at=datetime.now(),
		verified=False
	)
	return profile


def store_profile(profile: PersonProfile) -> Dict[str, Any]:
    """å°†æ¡£æ¡ˆå†™å…¥æœ¬åœ°JSONå­˜å‚¨ï¼Œè¿”å›ä¿å­˜åçš„å­—å…¸"""
    ensure_storage()
    persons = load_all_persons()
    record = profile.model_dump(mode="json")
    persons.append(record)
    save_all_persons(persons)
    logger.info(f"å·²å¯¼å…¥äººç‰©ä¿¡æ¯: {profile.name} ({profile.id})")
    log_audit("PERSON_IMPORT", profile.name, details=f"person_id={profile.id}")
    return record


def delete_person_by_id(person_id: str) -> bool:
    """æŒ‰IDåˆ é™¤äººç‰©ï¼Œè¿”å›æ˜¯å¦åˆ é™¤æˆåŠŸ"""
    ensure_storage()
    persons = load_all_persons()
    new_persons = [p for p in persons if str(p.get('id')) != str(person_id)]
    if len(new_persons) == len(persons):
        return False
    save_all_persons(new_persons)
    logger.info(f"å·²åˆ é™¤äººç‰©ä¿¡æ¯: {person_id}")
    log_audit("PERSON_DELETE", str(person_id), details="deleted from JSON store")
    return True


def _extract(pattern: re.Pattern, text: str) -> str:
    m = pattern.search(text)
    return m.group(1).strip() if m else None


def _search(pattern: re.Pattern, text: str) -> str:
    m = pattern.search(text)
    if not m:
        return None
    return m.group(0)


def extract_emails(text: str) -> List[str]:
    return [m.group(0) for m in EMAIL_REGEX.finditer(text)]


def extract_phones(text: str) -> List[str]:
    """æå–ç”µè¯åˆ—è¡¨ï¼Œä¼˜å…ˆè¿”å›ä¸­å›½å¤§é™†æ‰‹æœºå·ï¼Œå…¶æ¬¡åº§æœºï¼›æ’é™¤èº«ä»½è¯ç­‰é•¿æ•°å­—ã€‚"""
    candidates: List[str] = []
    for label in ['æ‰‹æœºå·', 'æ‰‹æœº', 'ç”µè¯', 'è”ç³»ç”µè¯', 'Phone', 'Tel']:
        for line in text.splitlines():
            if label in line:
                for m in MOBILE_REGEX.finditer(line):
                    candidates.append(m.group(1))
                for m in LANDLINE_REGEX.finditer(line):
                    area, num = m.group(1), m.group(2)
                    candidates.append(f"{area}-{num}")
    for m in MOBILE_REGEX.finditer(text):
        candidates.append(m.group(1))
    for m in LANDLINE_REGEX.finditer(text):
        area, num = m.group(1), m.group(2)
        candidates.append(f"{area}-{num}")
    filtered: List[str] = []
    for c in candidates:
        if ID_REGEX.search(c):
            continue
        if c.isdigit() and len(c) != 11 and '-' not in c:
            continue
        if c.replace('-', '').isdigit() and len(c.replace('-', '')) == 11:
            if c.replace('-', '')[0] != '1':
                continue
        if c not in filtered:
            filtered.append(c)
    filtered.sort(key=lambda s: 0 if s.replace('-', '').isdigit() and len(s.replace('-', '')) == 11 else 1)
    return filtered


def extract_addresses(text: str) -> List[str]:
    addrs: List[str] = []
    for line in text.splitlines():
        m = ADDRESS_LABEL_REGEX.search(line)
        if m:
            addrs.append(m.group(1).strip())
    return addrs


def extract_id_numbers(text: str) -> List[str]:
    ids: List[str] = []
    for m in ID_REGEX.finditer(text):
        ids.append(m.group(0))
    for m in ID15_REGEX.finditer(text):
        ids.append(m.group(0))
    return deduplicate_preserve_order(ids)


def extract_license_plates(text: str) -> List[str]:
    plates = [m.group(0) for m in LICENSE_PLATE_REGEX.finditer(text)]
    return deduplicate_preserve_order(plates)


def try_parse_date(text_value: Optional[str]) -> Optional[datetime]:
    if not text_value:
        return None
    s = text_value.strip()
    # å¸¸è§æ ¼å¼ï¼š1996å¹´02æœˆ19æ—¥ / 1996å¹´02æœˆ / 1996-02-19 / 1996/02/19 / 1996-02
    patterns = [
        r"(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥",
        r"(\d{4})å¹´(\d{1,2})æœˆ",
        r"(\d{4})-(\d{1,2})-(\d{1,2})",
        r"(\d{4})/(\d{1,2})/(\d{1,2})",
        r"(\d{4})-(\d{1,2})",
        r"(\d{4})/(\d{1,2})"
    ]
    for p in patterns:
        m = re.search(p, s)
        if m:
            try:
                y = int(m.group(1))
                mon = int(m.group(2)) if m.lastindex and m.lastindex >= 2 else 1
                d = int(m.group(3)) if m.lastindex and m.lastindex >= 3 else 1
                if 1900 <= y <= 2100 and 1 <= mon <= 12 and 1 <= d <= 31:
                    return datetime(y, mon, d)
            except Exception:
                continue
    # ä»…å¹´
    m = re.search(r"(\d{4})å¹´", s)
    if m:
        try:
            y = int(m.group(1))
            if 1900 <= y <= 2100:
                return datetime(y, 1, 1)
        except Exception:
            pass
    return None


def add_attr(attrs: Dict[str, Any], key: str, value: Any):
    """å‘è‡ªå®šä¹‰å±æ€§é‡Œè¿½åŠ é”®å€¼ï¼›è‹¥é”®å·²å­˜åœ¨ï¼Œåˆ™åˆå¹¶ä¸ºåˆ—è¡¨å¹¶å»é‡ã€‚"""
    if key is None:
        return
    k = str(key).strip()
    if not k:
        return
    v = value
    # å±•å¼€ç®€å•çš„å®¹å™¨
    if isinstance(v, list) and len(v) == 1:
        v = v[0]
    # è¿½åŠ é€»è¾‘
    if k not in attrs:
        attrs[k] = v
    else:
        if not isinstance(attrs[k], list):
            attrs[k] = [attrs[k]]
        if isinstance(v, list):
            for item in v:
                if item not in attrs[k]:
                    attrs[k].append(item)
        else:
            if v not in attrs[k]:
                attrs[k].append(v)


def deduplicate_preserve_order(items: List[str]) -> List[str]:
    seen = set()
    out = []
    for it in items:
        if it in seen:
            continue
        seen.add(it)
        out.append(it)
    return out


def extract_household_members(text: str) -> List[str]:
    """ä»æ–‡æœ¬é‡Œè§£æåŒæˆ·/åŒä½æˆå‘˜åï¼ˆç²—ç•¥ï¼‰ï¼Œè¿”å›å§“ååˆ—è¡¨ã€‚"""
    members: List[str] = []
    lines = text.splitlines()
    for line in lines:
        if any(lbl in line for lbl in HOUSEHOLD_LABELS):
            parts = re.split(r"[:ï¼š]", line, maxsplit=1)
            segment = parts[1] if len(parts) == 2 else line
            for name in split_names(segment):
                if name:
                    members.append(name)
    return members


def split_names(segment: str) -> List[str]:
    """å°†ä¸€æ®µæ–‡æœ¬æŒ‰å¸¸è§åˆ†éš”ç¬¦æ‹†åˆ†æˆå€™é€‰å§“åï¼Œè¿‡æ»¤æ˜æ˜¾éå§“åçš„é¡¹ã€‚"""
    raw = re.split(r"[ã€,ï¼Œ;ï¼›\s]+", segment)
    out: List[str] = []
    for token in raw:
        t = token.strip()
        if not t:
            continue
        if any(ch.isdigit() for ch in t):
            continue
        if len(t) > 10:
            continue
        if any(k in t for k in ['æ€§åˆ«','ç”·','å¥³','æˆ·','åº§','æ˜Ÿåº§','ç”Ÿè‚–','ä½å€','åœ°å€','å·ç ','è¯ä»¶']):
            continue
        out.append(t)
    return out


def _split_main_and_household_info(text: str) -> tuple[str, str]:
    """
    æ™ºèƒ½åˆ†ç¦»ä¸»äººç‰©ä¿¡æ¯å’ŒåŒæˆ·äººä¿¡æ¯
    è¿”å›: (ä¸»äººç‰©æ®µè½, åŒæˆ·äººæ®µè½)
    """
    lines = text.split('\n')
    main_lines = []
    household_lines = []
    in_household_section = False
    
    # å…³é”®è¯æ£€æµ‹
    household_keywords = ['åŒæˆ·äºº', 'åŒæˆ·', 'åŒä½äºº', 'å®¶åº­æˆå‘˜', '--', 'â•', 'â”']
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ£€æµ‹æ˜¯å¦è¿›å…¥åŒæˆ·äººåŒºåŸŸ
        if any(keyword in line for keyword in household_keywords):
            in_household_section = True
            household_lines.append(line)
            continue
            
        # æ£€æµ‹æ˜¯å¦æ˜¯åˆ†éš”çº¿ï¼ˆ18ä¸ªä»¥ä¸Šçš„-æˆ–å…¶ä»–ç¬¦å·ï¼‰
        if len([c for c in line if c in '-=â”â•']) >= 10:
            in_household_section = True
            household_lines.append(line)
            continue
            
        # å¦‚æœåŒ…å«èº«ä»½è¯å·æ¨¡å¼ï¼Œåˆ¤æ–­æ˜¯å¦å±äºä¸»äººç‰©
        id_matches = ID_REGEX.findall(line)
        if id_matches and not in_household_section:
            # ç¬¬ä¸€ä¸ªé‡åˆ°çš„èº«ä»½è¯ä¿¡æ¯è¢«è®¤ä¸ºæ˜¯ä¸»äººç‰©
            main_lines.append(line)
        elif id_matches and in_household_section:
            # åç»­çš„èº«ä»½è¯ä¿¡æ¯è¢«è®¤ä¸ºæ˜¯åŒæˆ·äºº
            household_lines.append(line)
        elif in_household_section:
            household_lines.append(line)
        else:
            main_lines.append(line)
    
    main_section = '\n'.join(main_lines)
    household_section = '\n'.join(household_lines)
    
    return main_section, household_section


def _parse_household_members(household_text: str) -> List[Dict[str, Any]]:
    """
    è§£æåŒæˆ·äººä¿¡æ¯æ®µè½ï¼Œè¿”å›åŒæˆ·äººåˆ—è¡¨
    """
    members = []
    
    # åˆ†è¡Œå¤„ç†
    lines = household_text.split('\n')
    current_member = {}
    
    for line in lines:
        line = line.strip()
        if not line or any(sep in line for sep in ['--', 'â”', 'â•', '=']):
            # åˆ†éš”çº¿ï¼Œä¿å­˜å½“å‰æˆå‘˜
            if current_member.get('name'):
                members.append(current_member)
            current_member = {}
            continue
            
        # æå–å§“å - æ”¹è¿›å§“åæå–é€»è¾‘
        name_match = re.search(r'([^,ï¼Œ\sï¼š:]{2,4})\s*[,ï¼Œ]', line)
        if name_match:
            current_member['name'] = name_match.group(1)
        else:
            # å°è¯•å…¶ä»–æ ¼å¼ï¼šå¦‚æœè¡Œå¼€å¤´æ˜¯å§“åï¼Œæ²¡æœ‰é€—å·åˆ†éš”
            first_word = line.split()[0] if line.split() else ''
            if first_word and len(first_word) >= 2 and len(first_word) <= 4 and not any(c.isdigit() for c in first_word):
                # è¿›ä¸€æ­¥è¿‡æ»¤å†’å·ç­‰æ ‡ç‚¹
                clean_name = first_word.strip('ï¼š:,ï¼Œã€‚')
                if clean_name and len(clean_name) >= 2:
                    current_member['name'] = clean_name
        
        # æå–æ€§åˆ«
        if 'ç”·' in line:
            current_member['gender'] = 'ç”·'
        elif 'å¥³' in line:
            current_member['gender'] = 'å¥³'
            
        # æå–èº«ä»½è¯å·
        id_match = ID_REGEX.search(line)
        if id_match:
            current_member['id_number'] = id_match.group(0)
            
        # æå–å‡ºç”Ÿæ—¥æœŸ
        birth_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', line)
        if birth_match:
            current_member['birth_date'] = f"{birth_match.group(1)}-{birth_match.group(2).zfill(2)}-{birth_match.group(3).zfill(2)}"
            
        # æå–ç”µè¯
        phone_matches = MOBILE_REGEX.findall(line)
        if phone_matches:
            current_member['phone'] = phone_matches[0]
            
        # å­˜å‚¨åŸå§‹è¡Œä¿¡æ¯
        if 'raw_lines' not in current_member:
            current_member['raw_lines'] = []
        current_member['raw_lines'].append(line)
    
    # ä¿å­˜æœ€åä¸€ä¸ªæˆå‘˜
    if current_member.get('name'):
        members.append(current_member)
    
    return members


def _extract_dynamic_fields(text: str) -> Dict[str, Any]:
    """
    æ™ºèƒ½æå–åŠ¨æ€å­—æ®µï¼ˆç”Ÿè‚–ã€æ˜Ÿåº§ã€å…¶ä»–æ ‡ç­¾ç­‰ï¼‰
    """
    custom_attrs = {}
    
    # ç”Ÿè‚–æ£€æµ‹
    zodiac_match = re.search(r'ç”Ÿè‚–\s*[:ï¼š]\s*([^ï¼Œ\s,ï¼›;]+)', text)
    if zodiac_match:
        custom_attrs['ç”Ÿè‚–'] = zodiac_match.group(1)
    
    # æ˜Ÿåº§æ£€æµ‹
    constellation_match = re.search(r'æ˜Ÿåº§\s*[:ï¼š]\s*([^ï¼Œ\s,ï¼›;]+)', text)
    if constellation_match:
        custom_attrs['æ˜Ÿåº§'] = constellation_match.group(1)
        
    # å†œå†ä¿¡æ¯
    lunar_match = re.search(r'([ç”²ä¹™ä¸™ä¸æˆŠå·±åºšè¾›å£¬ç™¸][å­ä¸‘å¯…å¯è¾°å·³åˆæœªç”³é…‰æˆŒäº¥]å¹´)', text)
    if lunar_match:
        custom_attrs['å†œå†å¹´ä»½'] = lunar_match.group(1)
        
    # å†œå†æ—¥æœŸ
    lunar_date_match = re.search(r'((?:æ­£|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å|å†¬|è…Š)æœˆ\s*(?:åˆ|å|å»¿|å…)?[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]{1,2})', text)
    if lunar_date_match:
        custom_attrs['å†œå†æ—¥æœŸ'] = lunar_date_match.group(1)
    
    # ç±è´¯ã€å‡ºç”Ÿåœ°ç­‰åœ°ç†ä¿¡æ¯
    birthplace_match = re.search(r'å‡ºç”Ÿåœ°\s*[:ï¼š]\s*([^ï¼Œ\nï¼›;]+)', text)
    if birthplace_match:
        custom_attrs['å‡ºç”Ÿåœ°'] = birthplace_match.group(1)
        
    # é€šç”¨é”®å€¼å¯¹æ£€æµ‹ (æ ¼å¼ï¼škey: value æˆ– keyï¼švalue)
    kv_matches = re.findall(r'([^ï¼š:\n]{1,10})\s*[:ï¼š]\s*([^ï¼Œ\nï¼›;]{1,50})', text)
    for key, value in kv_matches:
        key = key.strip()
        value = value.strip()
        
        # è¿‡æ»¤å·²çŸ¥å­—æ®µå’Œæ— æ„ä¹‰å­—æ®µ
        skip_keys = ['å§“å', 'æ€§åˆ«', 'ç”µè¯', 'æ‰‹æœº', 'åœ°å€', 'ä½å€', 'èº«ä»½è¯', 'å‡ºç”Ÿ', 'å¹´æœˆ', 'å·ç ']
        if any(skip in key for skip in skip_keys):
            continue
            
        if len(key) >= 2 and len(value) >= 1 and key not in custom_attrs:
            custom_attrs[key] = value
    
    return custom_attrs 